å¥½çš„ï¼Œä½ çš„æƒ³æ³•éå¸¸æœ‰è¿œè§ã€‚å°† `show` å‘½ä»¤è®¾è®¡å¾—ä¸ä¾èµ–äºç¡¬ç¼–ç çš„æ–‡ä»¶ç»“æ„ (`metadata.json`, `content.md`)ï¼Œè€Œæ˜¯åŠ¨æ€åœ°å±•ç¤ºèŠ‚ç‚¹ Git Tree ä¸­çš„æ‰€æœ‰å†…å®¹ï¼Œè¿™æå¤§åœ°å¢å¼ºäº†å®ƒçš„å¥å£®æ€§å’Œé¢å‘æœªæ¥çš„æ‰©å±•æ€§ã€‚åŒæ—¶ï¼Œæä¾› `--json` å’Œ `--extract` é€‰é¡¹å°†ä½¿å…¶æˆä¸ºä¸€ä¸ªå¼ºå¤§çš„è„šæœ¬å’Œè°ƒè¯•å·¥å…·ã€‚

æˆ‘å°†ç”Ÿæˆä¸€ä¸ªè®¡åˆ’æ¥å®ç°è¿™ä¸ªæ›´ä¼˜é›…ã€æ›´å¼ºå¤§çš„ `quipu show` å‘½ä»¤ã€‚

## [WIP] refactor(cli): å¢å¼º `show` å‘½ä»¤ä»¥æ”¯æŒ JSON è¾“å‡ºå’ŒåŠ¨æ€æ–‡ä»¶æå–

### ç”¨æˆ·éœ€æ±‚
éœ€è¦å¯¹æ–°åˆ›å»ºçš„ `quipu show` å‘½ä»¤è¿›è¡Œé‡æ„ï¼Œä»¥æ»¡è¶³ä»¥ä¸‹é«˜çº§éœ€æ±‚ï¼š
1.  **JSON è¾“å‡º**: æä¾›ä¸€ä¸ª `--json` æ ‡å¿—ï¼Œå°†èŠ‚ç‚¹å†…çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆ`metadata.json`, `content.md`, `intent.md` ç­‰ï¼‰åŠå…¶å†…å®¹ä½œä¸ºä¸€ä¸ª JSON å¯¹è±¡è¾“å‡ºåˆ° `stdout`ï¼Œä»¥æ–¹ä¾¿è„šæœ¬è°ƒç”¨ã€‚
2.  **åŠ¨æ€æ–‡ä»¶å‘ç°**: å‘½ä»¤ä¸åº”ç¡¬ç¼–ç æŸ¥æ‰¾ `metadata.json` å’Œ `content.md`ã€‚å®ƒåº”è¯¥èƒ½å¤ŸåŠ¨æ€åœ°å‘ç°å¹¶å±•ç¤ºèŠ‚ç‚¹å¯¹åº” Git Tree ä¸­çš„æ‰€æœ‰æ–‡ä»¶ã€‚
3.  **å•æ–‡ä»¶æå–**: æä¾›ä¸€ä¸ª `--extract <filename>` æ ‡å¿—ï¼Œç”¨äºä»…æå–å¹¶æ‰“å°æŒ‡å®šæ–‡ä»¶çš„åŸå§‹å†…å®¹ã€‚æ­¤åŠŸèƒ½åº”èƒ½ä¸ `--json` æ ‡å¿—ç»„åˆä½¿ç”¨ï¼ˆå°†æ–‡ä»¶å†…å®¹ä½œä¸º JSON å­—ç¬¦ä¸²è¾“å‡ºï¼‰ã€‚

### è¯„è®º
è¿™æ˜¯ä¸€ä¸ªå“è¶Šçš„æ¶æ„æ”¹è¿›ã€‚å®ƒå°† `quipu show` ä»ä¸€ä¸ªç®€å•çš„â€œä¿¡æ¯æŸ¥çœ‹å™¨â€æå‡ä¸ºä¸€ä¸ªçµæ´»çš„â€œæ•°æ®æå–å·¥å…·â€ã€‚åŠ¨æ€å‘ç°æ–‡ä»¶çš„èƒ½åŠ›ç¡®ä¿äº†å½“ Quipu çš„æ•°æ®æŒä¹…åŒ–åè®®ï¼ˆQDPSï¼‰æœªæ¥æ¼”è¿›ï¼ˆä¾‹å¦‚æ­£å¼åŠ å…¥ `intent.md`ï¼‰æ—¶ï¼Œæ­¤å‘½ä»¤æ— éœ€ä»»ä½•ä¿®æ”¹å³å¯å…¼å®¹ï¼Œè¿™æ˜¯ä¸€ç§éå¸¸ä¼˜é›…çš„è§£è€¦ã€‚ä¸ºè„šæœ¬æä¾›ç»“æ„åŒ–çš„ JSON è¾“å‡ºæ˜¯æå‡å¼€å‘è€…ä½“éªŒï¼ˆDXï¼‰çš„å…³é”®ä¸€æ­¥ã€‚

### ç›®æ ‡
1.  åœ¨ `HistoryReader` æ¥å£ä¸­æ·»åŠ ä¸€ä¸ª `get_node_blobs(commit_hash: str) -> Dict[str, bytes]` æ–¹æ³•ï¼Œç”¨äºè·å–èŠ‚ç‚¹å†…æ‰€æœ‰æ–‡ä»¶çš„åŸå§‹å­—èŠ‚å†…å®¹ã€‚
2.  åœ¨ `GitDB` ä¸­æ·»åŠ ä¸€ä¸ªåº•å±‚è¾…åŠ©æ–¹æ³• `get_blobs_from_tree`ã€‚
3.  åœ¨ `GitObjectHistoryReader` ä¸­å®ç°æ–°æ¥å£ï¼Œç›´æ¥è°ƒç”¨ `GitDB`ã€‚
4.  åœ¨ `SQLiteHistoryReader` ä¸­å®ç°æ–°æ¥å£ï¼Œé€šè¿‡å§”æ‰˜ç»™å…¶å†…éƒ¨çš„ `_git_reader` æ¥æä¾›æ­¤åŠŸèƒ½ï¼Œä»¥æ­¤ä½œä¸ºä¸€ç§å…¼å®¹ç­–ç•¥ï¼Œé¿å…ç«‹å³è¿›è¡Œå¤æ‚çš„æ•°æ®åº“è¿ç§»ã€‚
5.  å½»åº•é‡æ„ `quipu-cli` ä¸­çš„ `show.py`ï¼Œå®ç°å¯¹ `--json` å’Œ `--extract` å‚æ•°çš„å¤„ç†é€»è¾‘ã€‚

### åŸºæœ¬åŸç†
æˆ‘ä»¬å°†æ•°æ®è®¿é—®çš„ç²’åº¦ä»â€œè·å–ç‰¹å®šæ–‡ä»¶â€æ³›åŒ–ä¸ºâ€œè·å–èŠ‚ç‚¹å†…çš„æ‰€æœ‰æ–‡ä»¶â€ã€‚æ–°çš„ `get_node_blobs` æ–¹æ³•å°†æˆä¸º `show` å‘½ä»¤å”¯ä¸€çš„æ•°æ®æºã€‚è¯¥æ–¹æ³•è¿”å›ä¸€ä¸ªå­—å…¸ï¼Œé”®æ˜¯æ–‡ä»¶åï¼Œå€¼æ˜¯æ–‡ä»¶å†…å®¹çš„å­—èŠ‚æµã€‚

åœ¨ CLI å±‚ï¼Œ`show` å‘½ä»¤çš„é€»è¾‘å°†å˜ä¸ºï¼š
1.  è°ƒç”¨ `engine.reader.get_node_blobs()` è·å–æ•°æ®å­—å…¸ã€‚
2.  æ£€æŸ¥ `--extract` æ ‡å¿—ã€‚å¦‚æœå­˜åœ¨ï¼Œåˆ™ä»å­—å…¸ä¸­æå–ç‰¹å®šæ–‡ä»¶ã€‚
3.  æ£€æŸ¥ `--json` æ ‡å¿—ã€‚å¦‚æœå­˜åœ¨ï¼Œåˆ™å°†ç›®æ ‡æ•°æ®ï¼ˆæ•´ä¸ªå­—å…¸æˆ–æå–çš„å•ä¸ªæ–‡ä»¶å†…å®¹ï¼‰åºåˆ—åŒ–ä¸º JSON å¹¶æ‰“å°ã€‚
4.  å¦‚æœä¸¤ä¸ªæ ‡å¿—éƒ½ä¸å­˜åœ¨ï¼Œåˆ™è¿›å…¥â€œäººç±»å¯è¯»â€æ¨¡å¼ï¼Œéå†å­—å…¸ï¼Œæ ¹æ®æ–‡ä»¶åï¼ˆ`.json`, `.md` ç­‰ï¼‰æ™ºèƒ½åœ°é€‰æ‹©ä¸åŒçš„æ ¼å¼åŒ–æ–¹å¼è¿›è¡Œæ‰“å°ã€‚

`SQLiteHistoryReader` æ— æ³•ç›´æ¥ä»æ•°æ®åº“æ»¡è¶³æ­¤è¯·æ±‚ï¼Œå› ä¸ºå®ƒåªç¼“å­˜äº†éƒ¨åˆ†æ•°æ®ã€‚å› æ­¤ï¼Œå®ƒå°†æŠŠè¿™ä¸ªç‰¹å®šçš„è¯·æ±‚â€œç©¿é€â€åˆ°åº•å±‚çš„ `GitObjectHistoryReader`ï¼Œè¿™æ˜¯ä¸€ç§åŠ¡å®ä¸”é«˜æ•ˆçš„å®ç°ç­–ç•¥ã€‚

### æ ‡ç­¾
#intent/refine #flow/ready #priority/high #comp/cli #comp/engine #comp/interfaces #concept/history #scope/api #scope/dx #ai/instruct #task/domain/cli #task/object/show-command #task/action/refactor #task/state/continue

---

### Script

#### Acts 1: å‡çº§ `HistoryReader` æ¥å£

æˆ‘ä»¬å°†ç”¨ä¸€ä¸ªæ›´é€šç”¨çš„æ–¹æ³• `get_node_blobs` æ›¿æ¢ `get_node_metadata_raw`ã€‚

~~~~~act
patch_file
packages/quipu-interfaces/src/quipu/core/storage.py
~~~~~
~~~~~python
    @abstractmethod
    def get_node_metadata_raw(self, commit_hash: str) -> Optional[str]:
        """è·å–æŒ‡å®šèŠ‚ç‚¹æœªç»è§£æçš„åŸå§‹ metadata JSON å­—ç¬¦ä¸²ã€‚"""
        pass
~~~~~
~~~~~python
    @abstractmethod
    def get_node_blobs(self, commit_hash: str) -> Dict[str, bytes]:
        """è·å–ä¸€ä¸ªèŠ‚ç‚¹å†…æ‰€æœ‰æ–‡ä»¶çš„åŸå§‹äºŒè¿›åˆ¶å†…å®¹ï¼Œä»¥å­—å…¸å½¢å¼è¿”å› {filename: content_bytes}ã€‚"""
        pass
~~~~~

#### Acts 2: åœ¨ `GitDB` ä¸­æ·»åŠ åº•å±‚ Tree è§£æèƒ½åŠ›

ä¸ºäº†å®ç° `get_node_blobs`ï¼Œæˆ‘ä»¬éœ€è¦ä¸€ä¸ª `GitDB` çš„è¾…åŠ©å‡½æ•°æ¥è§£æ tree å¹¶æ‰¹é‡è·å– blobsã€‚

~~~~~act
patch_file
packages/quipu-engine/src/quipu/core/git_db.py
~~~~~
~~~~~python
        result = self._run(cmd)
        return result.stdout.encode("utf-8")

    def batch_cat_file(self, object_hashes: List[str]) -> Dict[str, bytes]:
        """
        æ‰¹é‡è¯»å– Git å¯¹è±¡ã€‚
~~~~~
~~~~~python
        result = self._run(cmd)
        return result.stdout.encode("utf-8")

    def get_blobs_from_tree(self, tree_hash: str) -> Dict[str, bytes]:
        """è§£æä¸€ä¸ª Tree å¯¹è±¡ï¼Œå¹¶è¿”å›å…¶åŒ…å«çš„æ‰€æœ‰ blob æ–‡ä»¶çš„ {filename: content_bytes} å­—å…¸ã€‚"""
        # 1. è·å– Tree çš„å†…å®¹
        tree_content_bytes = self.cat_file(tree_hash, "tree")
        tree_content = tree_content_bytes.decode("utf-8", "ignore")

        # 2. è§£æ Tree å†…å®¹ä»¥è·å– blob å“ˆå¸Œ
        # æ ¼å¼: <mode> <type> <hash>\t<filename>
        blob_info = {}
        for line in tree_content.strip().splitlines():
            parts = line.split()
            if len(parts) == 4 and parts[1] == "blob":
                blob_hash, filename = parts[2], parts[3]
                blob_info[filename] = blob_hash

        if not blob_info:
            return {}

        # 3. æ‰¹é‡è·å–æ‰€æœ‰ blob çš„å†…å®¹
        return self.batch_cat_file(list(blob_info.values()))

    def batch_cat_file(self, object_hashes: List[str]) -> Dict[str, bytes]:
        """
        æ‰¹é‡è¯»å– Git å¯¹è±¡ã€‚
~~~~~

#### Acts 3: åœ¨åç«¯å®ç°æ–°æ¥å£

é¦–å…ˆæ˜¯ `GitObjectHistoryReader` çš„åŸç”Ÿå®ç°ã€‚

~~~~~act
patch_file
packages/quipu-engine/src/quipu/core/git_object_storage.py
~~~~~
~~~~~python
    def get_node_metadata_raw(self, commit_hash: str) -> Optional[str]:
        """ä» Git å¯¹è±¡ä¸­æŒ‰éœ€è¯»å–å¹¶è¿”å› metadata.json çš„å†…å®¹ã€‚"""
        try:
            # 1. Get Tree Hash from Commit
            commit_bytes = self.git_db.cat_file(commit_hash, "commit")
            tree_line = commit_bytes.split(b"\n", 1)[0].decode("utf-8")
            if not tree_line.startswith("tree "):
                raise ValueError("Invalid commit object format")
            tree_hash = tree_line.split()[1]

            # 2. Get metadata.json Blob Hash from Tree
            tree_content_map = self.git_db.batch_cat_file([tree_hash])
            if tree_hash not in tree_content_map:
                return None
            tree_content = tree_content_map[tree_hash]
            entries = self._parse_tree_binary(tree_content)
            blob_hash = entries.get("metadata.json")

            if not blob_hash:
                return None  # No metadata found

            # 3. Read Blob content
            content_bytes = self.git_db.cat_file(blob_hash)
            return content_bytes.decode("utf-8", errors="ignore")

        except Exception as e:
            logger.error(f"Failed to lazy load raw metadata for commit {commit_hash[:7]}: {e}")
            return None
~~~~~
~~~~~python
    def get_node_blobs(self, commit_hash: str) -> Dict[str, bytes]:
        """ä» Git å¯¹è±¡ä¸­è¯»å–èŠ‚ç‚¹çš„æ‰€æœ‰æ–‡ä»¶å†…å®¹ã€‚"""
        try:
            # 1. Get Tree Hash from Commit
            commit_content = self.git_db.cat_file(commit_hash, "commit").decode("utf-8", "ignore")
            tree_line = commit_content.split("\n", 1)[0]
            if not tree_line.startswith("tree "):
                raise ValueError("Invalid commit object format")
            tree_hash = tree_line.split()[1]

            # 2. è§£æ Tree å¹¶æ‰¹é‡è·å–æ‰€æœ‰ blobs
            # We need to map blob hashes back to filenames.
            tree_content_bytes = self.git_db.cat_file(tree_hash, "tree")
            entries = self._parse_tree_binary(tree_content_bytes)

            blob_hashes = list(entries.values())
            blob_contents = self.git_db.batch_cat_file(blob_hashes)

            # Reconstruct the {filename: content} map
            result = {}
            for filename, blob_hash in entries.items():
                if blob_hash in blob_contents:
                    result[filename] = blob_contents[blob_hash]
            return result

        except Exception as e:
            logger.error(f"Failed to load blobs for commit {commit_hash[:7]}: {e}")
            return {}
~~~~~

ç„¶åæ˜¯ `SQLiteHistoryReader` çš„å§”æ‰˜å®ç°ã€‚

~~~~~act
patch_file
packages/quipu-engine/src/quipu/core/sqlite_storage.py
~~~~~
~~~~~python
    def get_node_metadata_raw(self, commit_hash: str) -> Optional[str]:
        """ä» SQLite é«˜æ•ˆè·å–åŸå§‹ meta_json å­—ç¬¦ä¸²ã€‚"""
        conn = self.db_manager._get_conn()
        try:
            cursor = conn.execute("SELECT meta_json FROM nodes WHERE commit_hash = ?", (commit_hash,))
            row = cursor.fetchone()
            return row[0] if row else None
        except sqlite3.Error as e:
            logger.error(f"Failed to get raw metadata for {commit_hash[:7]}: {e}")
            return None
~~~~~
~~~~~python
    def get_node_blobs(self, commit_hash: str) -> Dict[str, bytes]:
        """
        ä» Git å›æºè·å–èŠ‚ç‚¹çš„æ‰€æœ‰æ–‡ä»¶å†…å®¹ã€‚
        SQLite ç¼“å­˜ä¸å­˜å‚¨æ‰€æœ‰ blobï¼Œå› æ­¤æ­¤æ“ä½œæ€»æ˜¯å§”æ‰˜ç»™åº•å±‚çš„ git_readerã€‚
        """
        return self._git_reader.get_node_blobs(commit_hash)
~~~~~

#### Acts 4: é‡æ„ `show` CLI å‘½ä»¤

ç°åœ¨æˆ‘ä»¬ç”¨æ–°çš„æ•°æ®è·å–æ–¹å¼å’Œå‚æ•°å¤„ç†é€»è¾‘é‡å†™ `show.py`ã€‚

~~~~~act
write_file
packages/quipu-cli/src/quipu/cli/commands/show.py
~~~~~
~~~~~python
import json
import logging
from pathlib import Path
from typing import Annotated, Optional, Dict

import typer
from rich.console import Console
from rich.syntax import Syntax

from .helpers import engine_context
from ..config import DEFAULT_WORK_DIR

logger = logging.getLogger(__name__)


def _find_target_node(graph: Dict, hash_prefix: str):
    """è¾…åŠ©å‡½æ•°ï¼Œç”¨äºåœ¨å›¾ä¸­æŸ¥æ‰¾å”¯ä¸€çš„èŠ‚ç‚¹ã€‚"""
    matches = [
        node
        for node in graph.values()
        if node.commit_hash.startswith(hash_prefix) or node.output_tree.startswith(hash_prefix)
    ]
    if not matches:
        typer.secho(f"âŒ é”™è¯¯: æœªæ‰¾åˆ°å“ˆå¸Œå‰ç¼€ä¸º '{hash_prefix}' çš„å†å²èŠ‚ç‚¹ã€‚", fg=typer.colors.RED, err=True)
        raise typer.Exit(1)
    if len(matches) > 1:
        typer.secho(
            f"âŒ é”™è¯¯: å“ˆå¸Œå‰ç¼€ '{hash_prefix}' ä¸å”¯ä¸€ï¼ŒåŒ¹é…åˆ° {len(matches)} ä¸ªèŠ‚ç‚¹ã€‚",
            fg=typer.colors.RED,
            err=True,
        )
        raise typer.Exit(1)
    return matches[0]


def register(app: typer.Typer):
    @app.command()
    def show(
        ctx: typer.Context,
        hash_prefix: Annotated[str, typer.Argument(help="ç›®æ ‡çŠ¶æ€èŠ‚ç‚¹çš„ commit_hash æˆ– output_tree çš„å“ˆå¸Œå‰ç¼€ã€‚")],
        work_dir: Annotated[
            Path,
            typer.Option(
                "--work-dir", "-w", help="æ“ä½œæ‰§è¡Œçš„æ ¹ç›®å½•ï¼ˆå·¥ä½œåŒºï¼‰", file_okay=False, dir_okay=True, resolve_path=True
            ),
        ] = DEFAULT_WORK_DIR,
        json_output: Annotated[bool, typer.Option("--json", help="ä»¥ JSON æ ¼å¼å°†ç»“æœè¾“å‡ºåˆ° stdoutã€‚")] = False,
        extract: Annotated[Optional[str], typer.Option("--extract", "-e", help="ä»…æå–å¹¶æ˜¾ç¤ºæŒ‡å®šæ–‡ä»¶çš„å†…å®¹ã€‚")] = None,
    ):
        """
        æ˜¾ç¤ºæŒ‡å®šå†å²èŠ‚ç‚¹çš„è¯¦ç»†ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ‰€æœ‰å†…éƒ¨æ–‡ä»¶ã€‚
        """
        with engine_context(work_dir) as engine:
            target_node = _find_target_node(engine.history_graph, hash_prefix)
            blobs = engine.reader.get_node_blobs(target_node.commit_hash)

            if not blobs:
                typer.secho("ğŸ¤· æ­¤èŠ‚ç‚¹å†…éƒ¨æ— æ–‡ä»¶å†…å®¹ã€‚", fg=typer.colors.YELLOW, err=True)
                raise typer.Exit()

            # --- å¤„ç†æ•°æ®æå– ---
            output_data = {}
            if extract:
                if extract not in blobs:
                    typer.secho(f"âŒ é”™è¯¯: åœ¨èŠ‚ç‚¹å†…æœªæ‰¾åˆ°æ–‡ä»¶ '{extract}'ã€‚", fg=typer.colors.RED, err=True)
                    typer.secho(f"å¯ç”¨æ–‡ä»¶: {', '.join(blobs.keys())}", fg=typer.colors.YELLOW, err=True)
                    raise typer.Exit(1)
                # å°è¯•è§£ç ä¸ºå­—ç¬¦ä¸²ï¼Œå¤±è´¥åˆ™ä¿ç•™åŸå§‹å­—èŠ‚
                try:
                    output_data = blobs[extract].decode("utf-8")
                except UnicodeDecodeError:
                    output_data = blobs[extract]
            else:
                # è§£ç æ‰€æœ‰æ–‡ä»¶
                for filename, content_bytes in blobs.items():
                    try:
                        output_data[filename] = content_bytes.decode("utf-8")
                    except UnicodeDecodeError:
                        # å¯¹äºäºŒè¿›åˆ¶æ–‡ä»¶ï¼Œæˆ‘ä»¬å¯ä»¥é€‰æ‹©æ€§åœ°å¤„ç†ï¼Œä¾‹å¦‚æ˜¾ç¤ºå¤§å°æˆ– base64
                        output_data[filename] = f"<binary data, {len(content_bytes)} bytes>"

            # --- å¤„ç†è¾“å‡ºæ ¼å¼ ---
            if json_output:
                # æœºå™¨å¯è¯»çš„ JSON è¾“å‡ºåˆ° stdout
                try:
                    typer.echo(json.dumps(output_data, indent=2, ensure_ascii=False))
                except TypeError as e:
                    # å¦‚æœ output_data åŒ…å«åŸå§‹å­—èŠ‚ï¼Œjson.dumps ä¼šå¤±è´¥
                    typer.secho(f"âŒ é”™è¯¯: æ— æ³•å°†äºŒè¿›åˆ¶å†…å®¹åºåˆ—åŒ–ä¸º JSON: {e}", fg=typer.colors.RED, err=True)
                    raise typer.Exit(1)

            else:
                # äººç±»å¯è¯»çš„å¯Œæ–‡æœ¬è¾“å‡º
                console = Console()
                if extract:
                    # å¦‚æœæå–çš„æ˜¯ JSON æ–‡ä»¶ï¼Œé«˜äº®å®ƒ
                    if extract.endswith(".json"):
                        syntax = Syntax(output_data, "json", theme="default", line_numbers=True)
                        console.print(syntax)
                    else:
                        typer.echo(output_data)
                else:
                    # æ‰“å°æ‘˜è¦å¤´
                    ts = target_node.timestamp.strftime("%Y-%m-%d %H:%M:%S")
                    color = "cyan" if target_node.node_type == "plan" else "magenta"
                    tag = f"[{target_node.node_type.upper()}]"
                    typer.secho(f"[{color}]{ts} {tag:<9} {target_node.short_hash}[/{color}] - {target_node.summary}\n")

                    # éå†å¹¶æ™ºèƒ½æ‰“å°æ‰€æœ‰æ–‡ä»¶
                    for filename, content in sorted(output_data.items()):
                        console.rule(f"[bold]{filename}[/bold]", style="blue")
                        if filename.endswith(".json"):
                            syntax = Syntax(content, "json", theme="default", line_numbers=False)
                            console.print(syntax)
                        else:
                            console.print(content.strip())
                        console.print()
~~~~~

### ä¸‹ä¸€æ­¥å»ºè®®
- **ç¼–å†™å…¨é¢çš„æµ‹è¯•**ï¼šä¸º `quipu show` å‘½ä»¤ç¼–å†™æ–°çš„æµ‹è¯•ç”¨ä¾‹ï¼Œè¦†ç›– `--json`ã€`--extract` ä»¥åŠä¸¤è€…ç»„åˆçš„åœºæ™¯ï¼Œå¹¶éªŒè¯å½“è¯·æ±‚ä¸å­˜åœ¨çš„æ–‡ä»¶æ—¶æ˜¯å¦èƒ½æ­£ç¡®æŠ¥é”™ã€‚
- **æ›´æ–°æ–‡æ¡£**ï¼šè¿™æ˜¯ä¸€ä¸ªé‡è¦çš„ç”¨æˆ·åŠŸèƒ½ï¼Œéœ€è¦åœ¨ç”¨æˆ·æ‰‹å†Œä¸­è¯¦ç»†è®°å½• `quipu show` çš„ç”¨æ³•ï¼Œç‰¹åˆ«æ˜¯æ–°å¢çš„ `--json` å’Œ `--extract` é€‰é¡¹ã€‚
- **äºŒè¿›åˆ¶æ–‡ä»¶å¤„ç†**ï¼šå½“å‰å®ç°å¯¹äºŒè¿›åˆ¶æ–‡ä»¶ä»…æ˜¾ç¤ºå¤§å°ã€‚å¯ä»¥è€ƒè™‘åœ¨ `--json` æ¨¡å¼ä¸‹æä¾› `base64` ç¼–ç çš„é€‰é¡¹ï¼Œä»¥æ”¯æŒæ›´å¤æ‚çš„è„šæœ¬å¤„ç†éœ€æ±‚ã€‚
